[
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "John Andrew Kunze ‚Äì Curriculum Vitae",
    "section": "",
    "text": "Metadata Research Center, Drexel University  3141 Chestnut Street Philadelphia, PA 19104, USA  ORCID: 0000-0001-7604-8041 ¬†|¬† Linkedin: linkedin.com/in/jakkbl ¬†|¬† Github: jkunze  Mastodon: fosstodon.org/@jakkbl ¬†|¬† Bluesky: jakkbl.bsky.social  jkunze.net ¬†|¬† ARK Alliance\n\n\n\nRESEARCH AND DEVELOPMENT\nInformation Standards\nAggregate File Formats: primary author of the BagIt packaging format for disk-based or network-based storage and transfer of generalized digital content; co-author of the WARC (Web Archive) file format published as ISO 28500:2009; Standards Group lead for the International Internet Preservation Consortium (IIPC); member of the IIPC Technical Committee\nMetadata Semantic Standards: primary author of RFC 5013 Dublin Core (DC) metadata specification; founder and chair of the DC Kernel Metadata workgroup; chair of the National Information Standards Organization committee that moved the DC metadata specification to approval as NISO Z39.85 (2001); co-author and editor of the original DC metadata specification, RFC 2413; member of the DC Advisory Board; chair of the DC Agents and DC Date working groups; inventor in 1992 of the Z39.50 Info-1 generic attribute and element set, a precursor of DC\nMetadata Syntax Standards: author of the specification for encoding Dublin Core in HTML, RFC 2731; author of the ANVL (A Name Value Language) specification for simple labels and values in the style of RFC822; author of the TEMPER specification for dates; inventor of the Z39.50 Generic Record Syntax (GRS)\nUniform Resource Identifiers: in the context of the URI working group of the IETF, coined the term, URC (originally Uniform Resource Citation); contributed substantively to the URL standard itself, which includes authoring RFC 1736, functional requirements for the URL; led the creation of RFC 2056 describing Z39.50 URLs\nElectronic Permanence\nDigital Curation Tools: conceived a number of standalone tools, some incorporated into the Oxford Common File Layout (OCFL) specification, that support curation and preservation as embedded, distributed infrastructure rather than as part of a monolithic repository system that imposes a single archival culture on digital collections: Pairtree, Dflat, ReDD, Checkm, Namaste, CAN (Content Access Node); wrote and documented portable open-source software to support the tools; co-authored the curation micro-services approach being implemented at the California Digital Library (CDL)\nDataset Preservation: in December 2006 did a six-week Digital Curation Centre (DCC) fellowship with the Database Research Group at the University of Edinburgh, consulting with directors and staff at all four DCC sites regarding database preservation requirements and strategies; Preservation Group lead on a winning NSF DataNet proposal (led by University of New Mexico)\nWeb Archiving: wrote the core service vision in a winning NDIIPP grant proposal to the Library of Congress to create a service allowing curators to harvest and preserve web sites on demand, creating a geographically replicated archive that they can annotate, browse, and search; results of this 3-year grant used to advise congress on a national preservation strategy; provided critical technical leadership throughout implementation of CDL‚Äôs web archiving service, including technical collaboration with grant partners (e.g., UNT, NYU)\nPermanence Ratings: defined the framework for and participated centrally in the US National Library of Medicine‚Äôs multi-dimensional specification of permanence levels (about object availability, content invariance, and identifier validity); this work was published and the framework adopted by the US National Agriculture Library; built on this work for ARK persistence statements\nARK Persistent Identification Scheme: at NLM, analyzed 1998-era persistent naming schemes (URN, DOI, PURL, Handle, PDI (Persistent Document Identifier)), and formulated a new scheme, the Archival Resource Key (ARK), founded on the principle that persistence is purely about the service commitments of current object holders, not scheme syntax or the intent of name assigners that have no extant object service responsibility\nPersistent Identifier Infrastructure and Outreach:\nat CDL, built a generalized identifier minting, binding, and resolving system (‚Äúnoid‚Äù) that produces random, unique, non-sequential identifiers designed for permanence; these are compact, transcribable, semantically opaque, and furnished with a check character that guarantees each in the face of single digit and transcription errors; built and prototyped with a set of international partners the Name-To-Thing (N2T) resolver as a low-cost, low-risk consortially owned resolver for hundreds of identifier schemes (ARK, DOI, ChEBI, PDB, etc.); gave talks on these subjects at international meetings; founded the ARK Alliance (arks.org) to sustain ARK infrastructure and led its growth to over 1700 ARK organizations\nNetworked Information Systems\nTHUMP Protocol: designed The HTTP URL Mapping Protocol (THUMP), a set of URL-based conventions for retrieving information and conducting searches using a simple procedure call syntax in the URL query string and an ANVL syntax for returned records; worked with researchers at RENCI to extend it for dataset queries\nZ39.50 Protocol: at UC Berkeley, designed, wrote, and released the first complete Z39.50 client and server protocol engine, participating in the first three-way interoperability demonstration at NET ‚Äô92 with UC Office of the President (UCOP) and Penn State; worked within the Z39.50 Implementors Group to create and win adoption of the Generic Record Syntax in support of non-bibliographic applications; at NLM, designed and wrote a Z39.50 server for the MEDLINE database, and designed a generalized thesaurus mechanism (Structured Vocabulary Browse) to work with NLM‚Äôs MeSH headings; at UC San Francisco (UCSF), directed a team of programmers in developing a Web interface and HTTP/Z39.50 gateway to MEDLINE; for UCOP, developed the first production instance of the Web-based MELVYL system‚Äôs access methods for external Z39.50 databases (in this case, to PreMEDLINE running at NLM)\nOnline Information Systems: proposed, designed, wrote, and maintained in production a client-server CWIS information system, Infocal, which provided the first general online access to UC Berkeley‚Äôs main administrative datasets (schedule of classes, course catalog, phone directories, job vacancy listings, press releases); in the pre-Web era, this required extensive liaison with management and staff of campus units that maintained these datasets, and who were intimidated by information technology, unsure of the benefits of online access, and anxious about losing control over their data; Infocal was also an early client (1992) of both the Z39.50 and Web protocols (HTTP, Gopher, FTP)\nComputer Aided Instruction: designed, wrote, and maintained the Berkeley UNIX help system, a general-purpose online information system for exploring documentation files, directories, and executables (it had a user interface foreshadowing that of the Gopher browser); revived and significantly enhanced the UNIX learn program, a hypertext-based teaching tool from Bell Labs (late 1970s); both help and learn were disseminated globally with 4.2/4.3BSD (Berkeley Software Distribution); by 1982 the production help documentation tree was replicated on a daily basis across about twenty file servers on the Berkeley campus network\nDigital Libraries\nTobacco Control Research Collection: at UCSF, architected the American Legacy Foundation-funded Legacy National Tobacco Documents Library, some 40 million page images released by court order from the world‚Äôs major tobacco companies; during the implementation phase, focused on problems of poor indexing, corrupt or missing data, and incorporation of new material via web crawlers from ever-changing industry sites; wrote the main software components that support access via persistent identifiers and the browsing of individual document pages\nTobacco Document Digitization: created a detailed processing specification for digitizing shops to use in converting paper documents into standardized digital objects suitable for incorporation into digital library collections; this included scanning to create page images, OCRing to extract searchable text, and indexing (the hand-keying of metadata such as author, title, etc.)\nSearch Engine: wrote a new digital library searching and ranking engine designed to fill the gap between full text engines and fielded search systems, and to scale to millions of objects; the resulting system, tested on 1.5 million text objects and their metadata, performed fast boolean searching with wildcards and term list scanning\nElectronic Publishing: managed the subscription-based electronic publication of the UC Press book, ‚ÄúThe Cigarette Papers‚Äù; this experiment explored technical and marketing aspects of online publishing with access fees\nPrinter Cost Recovery: at UCSF, architected a network-based charging mechanism for publicly available print stations, a problem that plagued libraries across the country; the resulting system was probably the first low-cost solution enabling the library directly to manage all aspects of the authorization and routing technology involved\nAuthentication Infrastructure: at UCSF, architected the development of a network-queryable campus authentication infrastructure, requiring coordination with the campus units that supply payroll and student registration data on an ongoing basis; oversaw the development of various campus proxy servers\nComputer Operating Systems\nPerformance Analysis: wrote programs in S (precursor of the R language) to summarize and plot UNIX 4.2BSD file system activity; debugged kernel traces and a multi-strategy cache simulator based on them (presented at ACM SigOps, 1985)\nHeterogeneous Distributed Systems: worked on a project (1985) to bring up ULTRIX and VMS clients on a network of fully sharable computing resources, including file servers and print servers; wrote ULTRIX kernel code to implement a transport-level network interface, consisting of routines to generate server-side programs in a simple network command language\nCommand-Level Operating System Primitives: conceived a method of general-purpose software tool design; wrote three UNIX tools distributed with 4.2/4.3BSD using this method; these tools (‚Äújot‚Äù, ‚Äúrs‚Äù, and ‚Äúlam‚Äù) are distributed in current Mac OS X systems\nVLSI Coprocessor Design: worked on the design for a decimal coprocessor that IBM implemented along with Micro/370, an IBM/370 architecture on a chip; wrote and tested microcode for the decimal EDIT AND MARK instruction (1984)\nTerminal Capability Database: in the early 1980‚Äôs, maintained the Berkeley UNIX termcap file for a period of about five years; this data lives on (also in terminfo) as an integral part of modern Linux and UNIX-based systems\nCommunication/Instruction\nCommunity Service: chaired the Digital Library Federation‚Äôs (DLF) Developers Forum from 2005-2008, bringing it from near-extinction to thriving success; participated as panel organizer, as session chair, and/or as member of program committee for numerous conferences and meetings, such as PIDapalooza, IWAW, Open Repositories, iPRES, JCDL, ECDL, etc.; for several years presented at and advised the CENDI Persistent Identification Task Group (E-Government) Chaired the NSF DataONE Preservation and Metadata Working Group 2009-2014.\nIntellectual Property: consulted with the World Intellectual Property Organization in Geneva regarding design of a federated IP digital library (covering patents, trademarks, designs, and traditional knowledge), and developed a proof-of-concept demonstration system\nInstructional Support: at UCSF, managed the creation of a flexible software system for faculty to author and maintain course home pages\nInstruction: presented over a dozen ARK tutorials both online and in-person at conferences; at UC Berkeley, accrued ten years‚Äô experience in general consulting (advising) with users, students, and programmers on UNIX and IBM CMS; teaching assistant for undergraduate computer architecture; seven years‚Äô experience designing and teaching courses on UNIX and CMS; outside UCB, gave several week-long corporate training sessions (at AT&T, NCC, IRS) on Common Lisp and UNIX\nSIGWEB: created and organized a 400-person, all-day event at UCB for the SF Bay Area special interest group in state of the art network information retrieval applications; recruited most of the speakers and presented at this 1994 meeting\nCommon Lisp: as a private consultant, was designer and principal author of the 899-page manual, Common Lisp: the Reference (Addison-Wesley, 1988); supervised two co-authors for this work\n\nPROFESSIONAL HISTORY\n7/22 to present\nSENIOR RESEARCH ASSOCIATE ‚àí Drexel University\nGuided students and interns in the ongoing development of the YAMZ.net metadictionary and its use of ARK identifiers. Led the ARK Alliance expansion to over 1700 organizations. \n1/14 to 7/22\nIDENTIFIER SYSTEMS ARCHITECT ‚àí UCOP CDL\nLed the expansion of the EZID.cdlib.org identifier service and the N2T resolver. Added a formal agreement between n2t.net and identifiers.org to support compact identifiers for over 700 identifier schemes. Gave the keynote address (in French) at the 2018 ARK Summit at the BnF in Paris. As chair of the DataONE preservation and metadata working group, conceived and led creation of the YAMZ.net open, collaborative vocabulary building tool to mitigate against traditional inefficient, non-inclusive vocabulary consensus methods (eg, standard design by committee). Founded and led the ARK Alliance (arks.org) to sustain the ARK technical specification, its supporting registry, and the global ARK resolver. In 2022 there were over 1200 ARK organizations, including 10 national libraries, 145 universities, 184 archives, 75 journals, and major museums such as the Louvre, Smithsonian, and Frick.\n1/10 to 1/14\nASSOCIATE DIRECTOR, UC CURATION CENTER ‚àí UCOP CDL\nProvided leadership, strategy, and vision for creation of CDL‚Äôs approach to curation of research datasets and scholarly digital assets. Author of a number of micro-service specifications, including Pairtree, ReDD, Checkm, Namaste, and chief designer of the EZID identifier service and N2T resolver system. For the NSF DataONE initiative, I was technical lead on two of the first six NSF DataONE member node repositories (at CDL), leader of the Preservation and Metadata working group, member of the Leadership Team, and Core Cyberinfrastructure Team. I was heavily involved in the design and specification of the award-winning DataUp tool for curating spreadsheet data (CDL partnership with Micrsoft Research) and a simple approach to publishing data papers. Co-Lead on the implementation of YAMZ, an online crowdsourced metadata dictionary.\n2/03 to 12/09\nPRESERVATION TECHNOLOGIES ARCHITECT ‚àí UCOP CDL\nWhile leading strategic and technical aspects of the digital preservation program at CDL, I authored a web archiving service vision for a winning grant proposal ($2.4M) from the Library of Congress. I was technical lead for that project and worked at several levels on the design and implementation of CDL‚Äôs digital preservation repository. During this time I represented the CDL at the national level (NIH/NLM, NARA, GPO) and international level (British Library, DCC (UK), National Library of Canada, National Library of France, etc). I also served as CDL technical representative to national and international standards bodies (NISO, IETF, Dublin Core) and consortia (IIPC, DLF, W3C) and provided leadership for CDL‚Äôs Advanced Technology Group and programmer teams at NYU and UNT.\n5/01 to 1/03\nDIRECTOR OF TECHNICAL PLANNING, LNTDL ‚àí UCSF CKM and UCOP CDL\nWhile maintaining a partial appointment with the California Digital Library (CDL, at UC Office of the President), I provided technical leadership for the Legacy National Tobacco Documents Library hosted at the UC San Francisco Library and Center for Knowledge Management. Already the most important center for tobacco control documents, the UCSF Library was selected for this enormous new data set and I was asked in August 2000 to draft the initial collection architecture. I went on to architect and implement a major new and significantly different collection, detailing the outsourced processing requirements and developing a new search engine and interface.\nAt UCOP, I worked with the content management infrastructure group on defining persistent identifiers and common metadata in an attempt to consolidate and rationalize management of a diverse group of existing CDL datasets. There was also a strategic education (UC wide) and planning (eg, for open source library tools) component.\n5/98 to 4/01\nCONSULTANT, MEDICAL INFORMATICS ‚àí UCSF CKM and the NLM\nReceived a three-year grant (resembling a fellowship) from the NLM to research persistent naming on the internet and to advise NLM on what to do about electronic permanence. Across a range of proposals and literature, I analyzed methods, algorithms, performance, support implications, and social and institutional impacts. My initial recommendation resulted in the formation of an NLM group to define aspects of permanence directly relevant to NLM and designated for review by the Library of Congress and the National Agriculture Library. I also served as editor of this group‚Äôs permanence rating specification and was a member of a follow-on group formed to create a plan for implementing permanence at NLM. My final recommendation to NLM was to use persistent names having the properties described in the Archival Resource Key (ARK) draft. An ARK prototype system was set up at NLM.\nDuring this period I continued to speak regularly about my work, giving seminars at the Library of Congress, NLM (LHC) Computer Science Branch, UCB Computer Science department, UCSF Medical Informatics, UCB School of Information Management, and presentations to the annual meeting of the Coalition for Networked Information and various UC Library groups. I also maintained a fractional appointment to advise the UCSF Library on technical planning, including hiring and infrastructure. I served continuously during this time on the 9-campus University of California working group on technology, architecture, and standards for the California Digital Library (UCOP).\n10/95 to 4/98\nMANAGER, ADVANCED TECHNOLOGY GROUP ‚àí Center for Knowledge Management, UCSF\nLed a team of three programmers in designing and implementing several major projects. The Medsage project resulted in a production campus system for searching the MEDLINE database; components included a WWW interface, links to 71 electronic journals stored locally on an optical jukebox, an HTTP/Z39.50 gateway, and a MARC to HTML record translator. A second major project built a campus authentication, authorization, and charging infrastructure for multiple applications, initially print charging from public workstations; other applications included controlled access to electronic content, Web proxying for dialin authentication, and an X509 certificate authority.\n8/94 to 8/95\nLEAD PROGRAMMER/RESEARCHER ‚àí National Library of Medicine, Bethesda, MD\nReceived a one-year grant from the NLM: (a) to provide technical leadership for a team of five people setting up a Z39.50 server for MEDLARS databases, and (b) to research new protocols combining the strengths of Z39.50 and HTTP, particularly as they might apply to the NLM Sourcerer project (for discovering network resources and merging multi-server query results). During that year provided ongoing technical guidance to three people maintaining Infocal.\n9/89 to 9/95\nLEAD PROGRAMMER ‚àí Infocal Project, UC Berkeley\nAs instigator and technical leader of the Infocal project, my job was: (a) to design and implement software for an information server and one or more clients and (b) to design and supervise the maintenance of a growing body of campus information. The Infocal project won material support from Sun, Apple, DEC, CNI, and CNIDR. I made presentations on Infocal, on Z39.50, and on related work at professional meetings for ASIS, SIGUCCS, LITA (ALA), IEEE, HPCC, and BIREME. I supervised one position that created and monitored the mostly automatic update procedures for campus data providers.\nThe server was implemented in C, using as DBMS the UNIX filesystem and a small ad hoc search engine, avoiding administrative, functional, and performance problems of available DBMS products. The first (and only) client was written in C and TCL and functioned as a walkup campus kiosk system from about 200 terminals, as a telnet destination for anyone on the internet, and as an email robot for users who at least had an internet mail stop.\nWhile this client could establish Z39.50 sessions with other servers, the protocol had only just matured (Version 3) to the point where it interoperably supported the server‚Äôs browsing and non-bibliographic data requirements, so the client used a patchwork of older protocols. This and the risk of compromising the security of the campus network prevented the client code from being released to compete with other emerging systems (Web, Gopher, Prospero). The need to link to an increasing number of external targets in the multi-protocol internet led to my modifying the client to use the WWW protocol suite.\n9/77 to 8/89\nPROGRAMMER ‚àí 50-100% time, Information Systems and Technology, UC Berkeley\nAs programmer for six years, I worked in a team of four people in charge of UNIX, microcomputers, and networking, with one year as acting manager. Before then, I consulted, taught, and documented UNIX, IBM CMS, and Calidoscope (a Berkeley version of CDC 6400 Scope) operating systems. As a system administrator, I designed a standard campus Ultrix configuration for about 150 microvaxes and consulted with users on VAX and Macintosh computers.\n5/85 to 8/85\nRESEARCH INTERN ‚àí Digital Equipment Corp., Eastern Research Lab, Hudson, MA\nWorked with the distributed systems architecture team in researching, designing, and prototyping a heterogeneous distributed systems project. The main features of the design were a fast RPC-style protocol, a machine-independent network command language, and shared access to resources by ULTRIX, VMS, and MS-DOS. I worked on the ULTRIX kernel transport and network interface routines.\n\nEDUCATION\n BA, UC Berkeley, Double Major in Math and Computer Science (1982) (two courses short of a third major in Comparative Literature) Courses in Math and Physics at University of Nancy, France (1976) \nLanguages: C, LISP, PERL, Ruby, Python, S, Java, Pascal, FORTRAN, APL, PDP assembler, TCL, shell, etc. Partial fluency in French; knowledge of German and Spanish \n\nSELECTED PUBLICATIONS\nBuilding Community Consensus for Scientific Metadata with YAMZ, Jane Greenberg, Mat Kelly, John Kunze et al, Data Intelligence, March 2023, https://doi.org/10.1162/dint_a_00211\nFAIR Metadata: A Community-Driven Vocabulary Application, Christopher B. Rauch, Mat Kelly, John A. Kunze, Jane Greenberg, 2022, https://doi.org/10.1007/978-3-030-98876-0_16\nLost without context: Representing relationships between archival materials in the digital environment, The Lighting the Way Handbook: Case Studies, Guidelines, and Emergent Futures for Archival Discovery and Delivery, October 2021, book chapter, https://doi.org/10.25740/GG453CV6438\nInternet of Samples (iSamples): Toward an interdisciplinary cyberinfrastructure for material samples, Neil Davies, John Deck, Eric C Kansa, Sarah Whitcher Kansa, John Kunze, Christopher Meyer, Thomas Orrell, Sarah Ramdeen, Rebecca Snyder, Dave Vieglais, Ramona L Walls, Kerstin Lehnert, GigaScience, Volume 10, Issue 5, May 2021, giab028, https://doi.org/10.1093/gigascience/giab028\ncite-as: A Link Relation to Convey a Preferred URI for Referencing, H. Van de Sompel, M. Nelson, G. Bilder, J. Kunze, S. Warner, doi:10.17487/RFC8574, April 2019, https://www.rfc-editor.org/info/rfc8574\nA Computational Approach to Historical Ontologies, Mat Kelly, Jane Greenberg, Christopher Rauch, Sam Grabus, Joan Boone, John Kunze, and Peter Logan, 2020 IEEE International Conference on Big Data, https://doi.org/10.1109/bigdata50022.2020.9378268\nThe BagIt File Packaging Format (V1.0), Kunze, J., Littman, J., et al.¬†RFC 8493, doi:10.17487/RFC8493, October 2018, https://www.rfc-editor.org/info/rfc8493\nTen persistent myths about persistent identifiers, Kunze, J., August 2018, https://n2t.net/ark:/13030/c7gb1xh09\nUniform Resolution of Compact Identifiers for Biomedical Data, Wimalaratne, S, Juty, N, Kunze, J. et al.¬†Nature Scientific Data. May 2018. https://doi.org/10.1038/sdata.2018.95\nPersistence Statements: Describing Digital Stickiness, Kunze, J. et al.¬†Data Science Journal. 16, p.39, 2017. https://doi.org/10.5334/dsj-2017-039\nIdentifiers for the 21st century: How to design, provision, and reuse persistent identifiers to maximize utility and impact of life science data, Julie A. McMurry, Nick Juty, Niklas Blomberg, Tony Burdett, Tom Conlin, Nathalie Conte, M√É¬©lanie Courtot, John Deck, Michel Dumontier, Donal K. Fellows, Alejandra Gonzalez-Beltran, Philipp Gormanns, Jeffrey Grethe, Janna Hastings, Jean-Karim H√É¬©rich√É¬©, Henning Hermjakob, Jon C. Ison, Rafael C. Jimenez, Simon Jupp, John Kunze, Camille Laibe, Nicolas Le Nov√É¬®re, James Malone, Maria Jesus Martin, Johanna R. McEntyre, Chris Morris, Juha Muilu, Wolfgang M√É¬ºller, Philippe Rocca-Serra, Susanna-Assunta Sansone, Murat Sariyar, Jacky L. Snoep, Stian Soiland-Reyes, Natalie J. Stanford, Neil Swainston, Nicole Washington, Alan R. Williams, Sarala M. Wimalaratne, Lilly M. Winfree, Katherine Wolstencroft, Carole Goble, Christopher J. Mungall, Melissa A. Haendel, Helen Parkinson. PLOS Biology, 29 June 2017. https://doi.org/10.1371/journal.pbio.2001414\nDDI and Enhanced Data Citation, Hoyle, Larry, Mary Vardigan, Jay Greenfield, Sam Hume, Sanda Ionescu, Jeremy Iverson, John Kunze, Barry Radler, Wendy Thomas, Stuart Weibel, Michael Witt. IASSIST Quarterly, Fall 2015. http://iassistdata.org/sites/default/files/vol39_3-4_hoyle2.pdf\nCommunity Next Steps for Making Globally Unique Identifiers Work for Biocollections Data, Guralnick, Robert, Nico Cellinese, John Deck, Richard Pyle, John Kunze, Lyubomir Penev, Ramona Walls, Gregor Hagedorn, Donat Agosti, John Wieczorek, Terry Catapano, Roderic Page. ZooKeys 494: 133-154 2015. http://doi.org/10.3897/zookeys.494.9352\nKernel Metadata and Electronic Resource Citations (ERCs), Kunze, J; Janee, G; Turner, A. 2014. https://n2t.net/ark:/13030/c7sn0141m\nThe ARK Identifier Scheme: Lessons Learnt at the BnF and Questions Yet Unanswered, Peyrard, S√É¬©bastien, John Kunze, Jean-Philippe Tramoni. DC-2014 ‚Äì The Austin Proceedings. Oct 2014 https://n2t.net/ark:/13030/c7cj87k6m\nDataUp: A tool to help researchers describe and share tabular data, Strasser, Carly, John Kunze, Stephen Abrams, Patricia Cruse. [v1; ref status: approved 1, approved with reservations 1, http://f1000r.es/2n7] F1000Research 2014, 3:6 (doi: 10.12688/f1000research.3-6.v1)\nGuidelines on Recommending Data Repositories as Partners in Publishing Research Data, Callaghan, Sarah, Jonathan Tedds, John Kunze, et al.¬†IJDC Vol. 9, No.¬†1, pp.¬†152-163, 2014. http://dx.doi.org/10.2218/ijdc.v9i1.309\nProcesses and Procedures for Data Publication: A Case Study in the Geosciences, Sarah Callaghan, Fiona Murphy, Jonathan Tedds, Rob Allan, John Kunze, et al.¬†IJDC Vol 8, No 1, 2013. http://dx.doi.org/10.2218/ijdc.v8i1.253\nDataONE: Data Observation Network for Earth - Preserving Data and Enabling Innovation in the Biological and Environmental Sciences, Michener, William, Patricia Cruse, John Kunze, at al, D-Lib Magazine, 17:1/2, Jan/Feb 2011. http://www.dlib.org/dlib/january11/michener/01michener.html\nCalifornia Digital Library: Standardizing Digital Practices Across the University of California System‚Äù Kunze, John, Patricia Martin. NISO ISQ, Volume 22, Issue 1, Winter 2010. http://www.niso.org/apps/group_public/download.php/3676/QA_CDL_Kunze_Martin_%20isqv22no1.pdf\nPractices, Trends, and Recommendations in Technical Appendix Usage for Selected Data-Intensive Disciplines, Kunze, John, Patricia Cruse, Rachael Hu, et al, Report for the Gordon and Betty Moore Foundation, November 2010, https://n2t.net/ark:/13030/c7jw86m55\nAn Emergent Micro-Services Approach to Digital Curation Infrastructure, Abrams, Stephen, John Kunze, and David Loy, iPRES 2009: the Sixth International Conference on Preservation of Digital Objects. Proceedings, 4-11. Also ‚ÄúAn Emergent Micro-Services Approach to Digital Curation Infrastructure,‚ÄùInternational Journal of Digital Curation 5:1, 2010, 172-186.\nDirectory Description with Namaste Tags, Kunze, John. 2009 November 9. https://n2t.net/ark:/13030/c7g44hq41\nCheckm: a checksum-based manifest format, Kunze, John. 2009 Oct 30. https://n2t.net/ark:/13030/c72z12p53\nReverse Directory Deltas (ReDD), Kunze, John, Abrams, S, Hetzner, E, Loy, D. 2009 June 23. https://n2t.net/ark:/13030/c76m3337d\nPreservation Is Not a Place, Abrams, Stephen, Patricia Cruse, John Kunze. ISSN: 1746-8256. IJDC, Vol 4, No 1, 2009. http://ijdc.net/index.php/ijdc/article/download/98/73\nThe WARC File Format 1.0 (ISO 28500), Mohr, Gordon, Kunze, John, Stack, Michael, ISO Draft Standard, November 2008. https://n2t.net/ark:/13030/c7h98zc9w\nPairtrees for Collection Storage, Kunze, J, Haye, M, Hetzner, E, Reyes, M, Snavely, C. 2008 December 12. https://n2t.net/ark:/13030/c7kw57h9b\nThe BagIt File Packaging Format, Kunze, John, et al.¬†2008 December 1 http://tools.ietf.org/html/draft-kunze-bagit-01\nThe ARK Identifier Scheme, J. Kunze, R. Rodgers, May 2008 https://n2t.net/ark:/13030/c7cv4br18\nName-to-Thing (N2T) Resolver: Vision, J. Kunze, Nov 2007 https://n2t.net/ark:/13030/c7n58ck7f\nRFC 5013, The Dublin Core Metadata Element Set, J. Kunze, T. Baker, August 2007, http://www.ietf.org/rfc/rfc5013.txt\nPage Image Compression for Mass Digitization, S. Chapman, L. Duplouy, J. Kunze, S. Blair, et al.¬†Archiving 2007, Arlington, VA; May 2007; p.¬†37-42; ISBN / ISSN: 978-0-89208-270-4. http://www.ingentaconnect.com/content/ist/ac/2007/00002007/00000001/art00010\nTHUMP ‚Äì The HTTP URL Mapping Protocol, Kunze, John, Nassar, N, Gamiel, K. 2007 Feb 24. https://n2t.net/ark:/13030/c7bc3sx0w\nThe Entity (N2T) Resolver: low-risk, low-cost persistent identification, J. Kunze. iPRES 2006, Ithaca, NY; October 2006; presentation http://hdl.handle.net/1813/3688\nFuture-Proofing the Web: What We Can Do Today, Kunze, J. iPRES 2005, Goettingen, Germany; 16 Sept\nA Name-Value Language (ANVL), Kunze, J, Kahle, B, Masanes, J, Mohr, G.\n[ARK: One of] A Dozen Primers on Standards, J. Kunze, Computers in Libraries, Vol 24, Issue 2, February 2004, http://www.infotoday.com/cilmag/feb04/primers.shtml\nTowards Electronic Persistence Using ARK Identifiers, J. Kunze, Proceedings of the 3rd ECDL Workshop on Web Archives, August 2003, https://n2t.net/ark:/13030/c7n00zt1z\nA Metadata Kernel for Electronic Permanence, J. Kunze, Journal of Digital Information, Vol 2, Issue 2, January 2002, ISSN 1368-7506, https://n2t.net/ark:/13030/c7rr1pm49\nNISO/ANSI Z39.85-2001, Dublin Core Metadata Element Set, July 2001\nThe ARK Persistent Identifier Scheme, J. Kunze, R. Rodgers, March 2001, https://tools.ietf.org/html/draft-kunze-ark-01\nRFC 2731, Encoding Dublin Core Metadata in HTML, J. Kunze, December 1999, [obsoleted in RFC 5791] https://www.ietf.org/rfc/rfc2731\nRFC 2413, Dublin Core Metadata for Resource Discovery, S. Weibel, J. Kunze, C. Lagoze, M. Wolf, September 1998, https://www.ietf.org/rfc/rfc2413\nRFC 2056, Uniform Resource Locators for Z39.50, R. Denenberg, J. Kunze, D. Lynch, November 1996, https://www.ietf.org/rfc/rfc2056\nRFC 1736, Functional Recommendations for Internet Resource Locators, J. Kunze, February 1995. https://www.ietf.org/rfc/rfc1736\nRFC 1625, WAIS over Z39.50-1988, M. St.¬†Pierre, J. Fullton, K. Gamiel, J. Goldman, B. Kahle, J. Kunze, H. Morris, and F. Schiettecatte, (WAIS, Inc., CNIDR, Thinking Machines Corp., UC Berkeley, FS Consulting), June 1994 https://www.ietf.org/rfc/rfc1625\nThe Cigarette Papers: Issues in Publishing Materials in Multiple Formats, K. Butter, R. Chandler, J. Kunze, D-Lib Magazine, November 1996. https://doi.org/10.1045/november96-butter\nA Unified Element Vocabulary for Metadata, J. Kunze, Proceedings of W3C Distributed Indexing/Searching Workshop, (p71), Position paper, May 1996. https://doi.org/10.6084/m9.figshare.5212459\nEvolution of a Digital Library for the Health Sciences, J. Kunze, B. Warling, D-Lib Magazine, March 1996. https://doi.org/10.1045/march96-warling\nBasic Z39.50 Server Concepts and Creation, J. Kunze, NIST Special Publication 500-229 on Z39.50 Implementation Experiences, September 1995. https://doi.org/10.6084/m9.figshare.5212462\nResource Citations for Electronic Discovery and Retrieval, J. Kunze, November 1992, position paper distributed to the mailing list uri@bunyip.com proposing the term ‚ÄúURC‚Äù, referenced in https://www.ietf.org/proceedings/25.pdf page 503\nNonbibliographic Applications of Z39.50, J. Kunze, The Public-Access Computer Systems Review 3, no. 5 (1992): 4-30. https://journals.tdl.org/pacsr/index.php/pacsr/article/view/6061/5692\nCommon Lisp: the Reference, Addison-Wesley, 1988 (899 pages), principal author acknowledgement page xix. https://n2t.net/ark:/13960/t68350d1q\nA Trace-Driven Analysis of the UNIX 4.2 BSD File System, J. Ousterhout, H. Da Costa, D. Harrison, J. Kunze, M. Kupfer, J. Thompson, Proceedings of the Tenth ACM Symposium on Operating Systems Principles, 1985. https://doi.org/10.1145/323647.323631\nZ39.50 in a Nutshell (An Introduction to Z39.50) J. Kunze, R. P. C. Rodgers, Lister Hill National Center for Biomedical Communications, July 1995 http://www.nlm.nih.gov/pubs/staffpubs/rodgers/z39.50/z39.50.html"
  },
  {
    "objectID": "blog/about.html",
    "href": "blog/about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "John Andrew Kunze ‚Äì Biography",
    "section": "",
    "text": "Metadata Research Center, Drexel University\n3141 Chestnut Street Philadelphia, PA 19104, USA\nCV ¬†¬†|¬† ORCID: 0000-0001-7604-8041\nLinkedin: linkedin.com/in/jakkbl ¬†|¬† Github: jkunze\nMastodon: fosstodon.org/@jakkbl ¬†|¬† Bluesky: jakkbl.bsky.social\njkunze.net ¬†|¬† ARK Alliance\n\n\n\n\n\n\n\n\n    \n    \n    Your browser does not support the audio element.\n\n\n\n    \n    \n    Your browser does not support the audio element.\n\n\n\n    \n    \n    Your browser does not support the audio element.\n\n\n\n    \n    \n    Your browser does not support the audio element.\n\n\n\n    \n    \n    Your browser does not support the audio element.\n\n\n\nJohn Kunze is a pioneer in the theory and practice of digital libraries. His passion for creating and sharing free, open, pragmatic digital solutions has guided his long public sector career. As a Berkeley undergrad in computer science and mathematics, he wrote software that comes pre-installed in every Mac and Linux system. He had leading roles in establishing identifier standards (URL, ARK), metadata standards (Dublin Core), archiving standards (BagIt, WARC), the Z39.50 library protocol, UC Berkeley‚Äôs first Campus Wide Information System, and repository microservices used in HathTrust and OCFL. He is currently leading the ARK Alliance forward and serving as a senior research associate at Drexel University, where he is working on the crowdsourced vocabulary tool, yamz.net.\n\nParticipating in open source at the University of California (UC) Berkeley from 1978-1983, 20 years before that term was coined, Kunze began fixing BSD Unix bugs and writing tools that come pre-installed in today‚Äôs Mac and Linux systems (jot, lam, rs). During that time he maintained the global terminal capability database (termcap), created an online Unix help system, brought the Bell Labs Unix ‚Äúlearn‚Äù program and its computer-aided instruction scripts to life, and became principal author of the book Common Lisp: the Reference. Realizing that content is king in information technology, he became interested in working with libraries and archives.\nIn 1989 he proposed and began creating UC Berkeley‚Äôs first Campus Wide Information System (CWIS).* Into that system, called Infocal,‚Ä† he built in pre-web hypertext navigation (inspired by ‚Äúlearn‚Äù scripts), a custom search engine, and open access to (a) library catalog search via the then-new Z39.50 search and retrieval protocol, (b) major campus datasets previously available only on paper (course catalog, schedule of classes, phone directory, job vacancies), and (c) the World Wide Web. Interoperation with Z39.50 had never been demonstrated previously, requiring a heavy investment in several areas. This work included standards development, software development ‚Äì resulting in the release of the first complete open-source client-server codebase ‚Äì and the first true interoperability demonstration, conducted between UC Berkeley, Penn State University, and the UC Division of Library Automation.\nAs Infocal became web-aware, Kunze began to work with identifier standards. In 1994 he declined principal editorship of the URL specification, and instead agreed to write the functional requirements in an attempt to unblock the URL standard, which was at an impasse because the average URL link (web address) was seen to break (stop working) after about 44 days. His proposed standard permitted URLs to break and was published as RFC1736, resulting in the immediate approval of the first URL standard as RFC1738. As part of a 3-year fellowship at the US National Library of Medicine (NLM), he analyzed the persistent identifier landscape and in 2000 defined the framework for the NLM multi-dimensional permanence levels.\nTo counter the flood of broken URLs, Kunze created the ARK (Archival Resource Key) persistent identifier scheme in 2001 at the California Digital Library (CDL). With the goal of addressing broken links flexibly and affordably while leveraging the NLM permanence levels, he evolved the ARK specification, created the ARK resolver and registration infrastructure, and registered the first 600 ARK organizations. In 2018 with help from DuraSpace, he led the creation and growth of the ARK Alliance (arks.org). By the end of 2025, there were over 1720 ARK organizations, including 12 national libraries, 215 universities, 254 archives, 144 museums, 124 journals, and 59 scientific centers. The non-paywalled ARK identifier is vital for open knowledge linking across world cultural and scientific institutions, especially in the global South.\nMotivated by the Unix philosophy favoring simple, extensible tools that combine easily and by a distaste for siloed solutions, Kunze developed open source tools for ARKs that also work for non-ARK identifiers. The Name-to-Thing (N2T.net) resolver supports hundreds of compact identifier schemes, the EZID identifier service supports ARKs and DOIs (URNs, PURLs, and IGSNs were planned), the Noid (Nice Opaque Identifier) Tool mints billions of ARK and Handle identifiers, and THUMP specifies inflections for ARKs that work with any URL-based identifiers. He also co-authored RFC1625 (WAIS) and RFC2056 (Z39.50 URLs).\nA key takeaway from his protocol interoperability work, especially for nonbibliographic applications, was the notion of shared attributes such as title, author, and date. This inspired him to propose the Uniform Resource Citation (URC) in 1992 and to join the Dublin Core initiative in 1995 to focus on a new thing being called metadata. There he led publication of the world‚Äôs first metadata standards (RFC2413, RFC2731, ANSI/NISO Z39.85), upon which most metadata schemas are based: Schema.org, OAI-PMH, MODS, METS, EPUB, DataCite, Darwin Core, etc. Considering metadata to be far from finished, he created the minimalist Dublin Kernel based on his Z39.50 work, the TEMPER date format, and a vision (1996) of a kind of ‚ÄúDublin Mantle‚Äù that he that he would later implement as the YAMZ.net vocabulary builder.\nIn 2003 Kunze wrote the vision for a Library of Congress (LC) grant to harvest and preserve at-risk websites. Under that grant, he published the first draft of the WARC standard, now used in all large-scale web archiving (e.g., Internet Archive). To move files between archives, he worked with the LC team as principal author of the BagIt standard (RFC8493), which is widely deployed in libraries and archives (LC, Stanford, Cornell, Dryad, etc). He also created repository microservice specifications used in HathiTrust (Pairtree), BagIt (Oxum), and OCFL (Namaste).\n\n\n\n* Not everyone knows that a few years before the web appeared, dozens of custom-built state-of-the-art networked information systems were emerging at universities for the purpose of sharing diverse types of information with students, faculty, staff, and the general public. In this brief era of the Campus Wide Information System (CWIS), institutions of higher education effectively piloted the web insofar as they worked out presentation and maintenance of heterogeneous online data over network protocols such as FTP, NNTP, Z39.50, and Gopher. From the University of Minnesota, Gopher was the first CWIS software packaged for easy installation, and just as thousands of non-campus sites were adopting it, the WWW software‚Äôs winning hypertext capability overtook it.  ‚Ä† IPA pronunciation links üîä: Kunze /Ààk änziÀê/, Infocal /Àà…™nf…ô äk√¶l/, Noid /n…î…™d/, EZID /iÀêÀåziÀêa…™ÀådiÀê/, URL /juÀê…ëÀê…π…õl/"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "biography.html",
    "href": "biography.html",
    "title": "John Andrew Kunze ‚Äì Biography",
    "section": "",
    "text": "John Andrew Kunze is a computer scientist most known for his contributions to information systems and standards, and to the theory and practice of digital libraries. From his earliest work experiences at the University of California Berkeley (UCB), he developed an affinity for public service and a taste for what would come to be known twenty years later as ‚Äúopen source‚Äù, and so he remained with the University of California for most of his career.\nHe was born in 1958 in Boston, Massachusetts, the fourth of the five children of Alice Caroline Gaar and Ray Alden Kunze. His father was a math professor and his mother a PhD candidate in comparative literature. He attended public schools in St.¬†Louis, Missouri and Corona del Mar, California, played tennis for his high school team, studied piano and organ, and gave several church organ performances starting at age 16. After a year in Nancy, France during his father‚Äôs sabbatical, John returned to enroll at UCB in 1977, where he became a double major in computer science and mathematics, and was two courses short of a third major in French and German comparative literature. At UCB he also picked up squash, played for the university team, and remains an active member of the Berkeley squash community. Except for his first term, he paid all his university and living expenses working a half-time job at the UCB Computer Center. There his first boss had been hired as a result of successfully hacking the student database using a punched card deck to change one of his computer science class grades from an A- to an A.\nJohn started contributing to the Berkeley Software Distribution (BSD) of Unix (the basis of Mac OS) by fixing bugs as a freshman in 1977. It began when his copious emailed bug reports started to be returned with the note ‚Äúhere‚Äôs the code ‚Äì fix them yourself‚Äù. Coinciding with his user support job, he wrote a general Unix ‚Äúhelp‚Äù program, revived the broken Unix ‚Äúlearn‚Äù program (an early script-driven computer-aided-instruction system), maintained the ‚Äútermcap‚Äù database, and, inspired by APL operators, created the ‚Äújot‚Äù, ‚Äúlam‚Äù, and ‚Äúrs‚Äù utilities found on modern Mac computers. In 1985 he became a co-author of the highly cited ‚ÄúA Trace-Driven Analysis of the UNIX 4.2 BSD File System‚Äù, supplying graphs scripted using S, the pre-cursor of R.\nIn 1988 he became the principal author of the 899-page book, ‚ÄúCommon Lisp: the Reference‚Äù (he also implemented automated testing for all its coding examples). His oldest brother, Fritz, was a founder of the Lisp support company, Franz, Inc.¬†Early experience with ‚Äúhelp‚Äù and ‚Äúlearn‚Äù taught John that ‚Äúcontent was king‚Äù and led in 1989 to his proposing and creating ‚ÄúInfocal‚Äù (pronounced info-CAL), UCB‚Äôs first Campus-Wide Information System (CWIS). Written in source-available C and Tcl, the system was an early rival of the WWW, had its own hypertext (modeled on ‚Äúlearn‚Äù scripts), a custom search engine, and the brand new Z39.50 search and retrieval protocol.\nThat work brought him in contact with Tim Berners-Lee (inventor of the WWW) and Brewster Kahle (founder of WAIS and the Internet Archive) and, by 1992, Infocal went from being a rival of the WWW to an early user of its multi-protocol client library. Infocal was offered free to the public from 200 campus kiosks and from remote Telnet clients, and it participated in the first Z39.50 interoperability demonstration (at the Net ‚Äò92 conference in Washington, DC, the other two participants being the Penn State University Library and the University of California‚Äôs Division of Library Automation). It provided the Berkeley campus‚Äô first experience of online access to each of four major UCB datasets: the schedule of classes, course catalog, job vacancy listings, and faculty funding opportunities. All technical, protocol, policy, data, and user interface work was done with only 2.5 full time staff positions. Organizing an open-source code release of Infocal was impossible given the burdens of running a production service, maintaining datasets, and adapting Z39.50 and working with its standards bodies to accommodate non-bibliographic applications.\nFor better or worse, Z39.50 had plunged John into the world of standards (ANSI, NISO, ISO, IEEE, IETF) where he was drawn by the IETF‚Äôs innovative culture and lightweight, high impact specifications. It was clear that Berners-Lee‚Äôs combination of automated FTP plus hypertext ‚Äì minus search ‚Äì was the winning approach, and that the URL and possibly the URN would be key. Kahle‚Äôs Wide Area Information Service (WAIS, based on Z39.50-1988) and John‚Äôs Infocal would not have long futures. It soon became a priority to finish standardizing the URL/URI since the spec had come to an impasse. To get things moving, the URI working group, led by Alan Emtage, asked John to write up the URL requirements (RFC1736) and to take over from Berners-Lee as main editor of the spec. John only had time to accept the former commitment, and offered the latter to Larry Masinter. RFC1736 succeeded in getting the URI group unstuck, largely by explicitly allowing links to be ‚Äúimpermanent‚Äù, and a consensus on the URL standard was achieved shortly thereafter.\nThe cost of the hard-won, drawn-out consensus battle was high. Burnout caused the IETF URI working group to lose many key people, along with their collective memory, while critical work was unfinished in resource description (URC) and its persistent identifier hypothesis (URN). In an earlier encounter with the former, John coined the term URC (Uniform Resource Citation) in 1992 as a cluster of descriptive elements that could be displayed when a user‚Äôs mouse hovered over a hyperlink. He was wrapping up his involvement in Z39.50 (RFC1625, RFC2056) and saw a way to leverage the unique Z39.50 notion of standardized ‚Äúsearch access points‚Äù, or data elements supporting discovery. In 1993 he brought this perspective to the IETF IIIR working group as it took up the topic of ‚ÄúData Elements‚Äù, described then as ‚Äúmetainformation‚Äù for internet resources. The once-obscure term, ‚Äúmetadata‚Äù, suddenly came into wide use in information systems starting with the Dublin Core initiative in 1995.\nJohn drafted the Dublin Core consensus and shepherded the first three Dublin Core specifications through the standards processes: RFC2413, RFC2731, and ANSI/NISO Z39.85. Dublin Core is arguably the most influential internet metadata standard, with countless descendant ontologies and very broad support among digital repositories, harvesters, and search indexes. Aware of its shortcomings (nothing is perfect), he proposed Dublin Kernel metadata to add teeth to the ‚Äúall elements are optional‚Äù Dublin Core. Along with Kernel metadata, he created a pre-YAML-like syntax (ERC/ANVL) and a date format (TEMPER) that would support ranges and approximate dates. In 1996 he wrote up a vision of a crowd-sourced cross-domain superset vocabulary ‚Äì a sort of ‚ÄúDublin Mantle‚Äù ‚Äì that would be realized much later as yamz.net. In 1994 he organized the 8th San Francisco Bay Area SIGWEB meeting, a 400-person, all-day conference held at UCB. He then left Berkeley to take up a one-year fellowship with the National Library of Medicine (NLM) after a large cross-campus committee formally recommended that Berkeley‚Äôs future lay with the Gopher system (the Infocal team managed to append a minority recommendation in favor of the WWW). If content was king, the place to be was the library world.\nIn 1995 John handed off termcap maintenance to Eric Raymond (author of The Cathedral and the Bazaar) and joined the Center for Knowledge Management (CKM) in the Library of the University of California San Francisco (UCSF). The CKM had launched the SIGWEB meeting series and quite recently had been at the heart of two controversies. Three CKM staff members had departed to create Eolas, a firm that many saw as a patent troll and which later won a patent judgement of over $550 million. Unrelated, the CKM had also just exploited the then new image delivery capabilities of the web to mount online scanned images of stolen tobacco company documents, an act that would become a landmark in tobacco litigation, academic freedom, government policy, and the fight against corporate control of information. Taking up the latter, he created systems and protocols for digitizing, searching, and identifying industry documents that would help UCSF build a multi-million-page document library that has been a crucial resource in the global regulation of tobacco.\nIn 1998 John resumed a fellowship with the NLM, where he was asked to evaluate existing approaches to the problem of persistently referencing things that URLs linked to: URN, Handle, PURL, and DOI. In his view these approaches had all accepted a flawed hypothesis that, in this instance, reduced a complex, socio-organizational service-sustainability problem to one of simple ‚Äúindirection‚Äù. He suspected the blame lay with the dazzling success that DNS had recently achieved in using indirection to make hostnames persistent. He argued that even if one accepted the hypothesis, none of the existing approaches were needed since anyone who had a web server and a carefully chosen hostname already possessed a ‚Äúsolution‚Äù (unless one also wanted to hire a junior developer to create a simple admin interface to maintain a two-column indirection table). In 2000 he co-authored a set of NLM ‚Äúpermanence ratings‚Äù to specify the multi-dimensional ways in which a web resource might change ‚Äì the object itself, its content, its identifier ‚Äì within an institution‚Äôs commitment to that resource. He finished the NLM work with a recommendation not to bother with existing persistent identifier (PID) systems when creating links, and just to assign and manage URLs carefully according to a short list of guiding principles.\nJohn thought he was done with PIDs, but that wasn‚Äôt to be when he joined the California Digital Library (CDL) in 2001. In devising a strategy for link persistence, his NLM work didn‚Äôt help one gauge the persistence of URLs received from elsewhere. The vast majority of URLs in the world are not meant to persist, so it seems useful to be able to distinguish those that are meant to persist. This led to his creating the Archival Resource Key (ARK), a scheme for a distinguishable URL that can reference a resource of any type, without fees, and that is globally unique independent of hostname or HTTP. To gauge its persistence, a user can ‚Äúinflect‚Äù the ARK by adding ‚Äú??‚Äù to the end in order to request metadata and a nuanced (non-binary) commitment statement. It combined his guiding principles, the NLM permanence ratings, the CDL use case, ERC/ANVL Kernel metadata, and his new scheme agnostic protocol (THUMP) for inflecting URLs. For ARK implementers, he created the open source Noid (Nice Opaque Identifier) software. Noid was a fast scalable tool that could mint, bind, and resolve identifiers of any kind. It was not purely an ARK tool, since he had conceived the ARK partly out of opposition to the exclusionary practices adopted by other identifier systems that sought to capture markets and lock users in. So while most people use Noid with ARKs, some use it with Handles.\nIn 2003 John began working with the CDL‚Äôs new preservation program. The CDL adopted ARKs along with other University of California campuses. He gave presentations on ARKs once or twice a year and within a decade 168 institutions had registered to use them, including heavy adopters such as the National Library of France and the Internet Archive. While working on a Library of Congress grant, he wrote the BagIt packaging format (RFC8493) and drafted the first version of the web archiving (WARC) standard, both of which are widely used in digital repository and web harvesting systems. The latter uses an early version of his ANVL metadata format. During that time he also specified and implemented a handful of digital repository microservices used at CDL and other digital libraries across the world: Pairtree, Namaste, ReDD, oxum, Checkm. Several of these were re-implemented independently based on his specifications and are used in such places as the HathiTrust and OCFL-based systems. Although ARKs are decentralized by design, he created N2T.net in response to demand for a centralized ARK resolver. He also conceived the EZID system in response to demand for a front-end identifier management microservice that could be used with multiple storage repositories. N2T and EZID were unique in the world for their scheme-agnostic approach to managing and resolving individual identifiers. Neither system was purely about ARKs for the same reason that Noid is not purely an ARK tool.\nIn 2005 John resurrected the Digital Library Federation‚Äôs Developers Forum and chaired it for three years. In 2006 he went on a six-week fellowship with the University of Edinburgh to consider the emerging topic of PIDs and citations for scientific data. That fellowship resulted in CDL being invited to join the 5-year NSF DataONE grant, where he chaired the Preservation and Metadata Working Group starting in 2009. During this period he was also technical lead on collaborations with Microsoft Research and the Moore Foundation.\nThe DataONE involvement led to his creating yamz.net, which was the first realization of his 1996 vision for a crowdsourced ‚Äúmetadictionary‚Äù vocabulary builder. Around this time John created the ‚Äúsuffix passthrough‚Äù capability that permits N2T to resolve millions of identifiers on the basis of one registered identifier (similar to PURL‚Äôs ‚Äúpartial redirect‚Äù). In 2017 a formal collaboration with identifiers.org resulted in their adopting N2T‚Äôs ‚Äúcompact identifier‚Äù syntax and N2T‚Äôs adopting their curated ruleset of 600+ identifier schemes. That same year saw registration of the 419th ARK institution and his publication of a ‚Äúpersistence‚Äù vocabulary that considerably expanded on the NLM permanence ratings from 2000. In 2018 the National Library of France held a two-day, 350-person French-language ARK Summit in Paris, for which he gave the keynote address.\nBy the end of 2018, with CDL‚Äôs support to focus on ARKs, John spearheaded creation of what would become the ARK Alliance (arks.org). Over 500 institutions had registered and created over 8 billion ARKs, and for the first time ARKs had their own organization, including an advisory group and outreach, technical, and sustainability working groups. With the registration rate roughly doubling each year, four years later there were over 1000 ARK institutions. In 2022 John left the University of California to work with partners to keep the ARK Alliance moving towards self-sufficiency and to pursue his interest in the Decentralized Web (DWeb)."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "xb",
    "section": "",
    "text": "No matching items"
  }
]